RMSprop

First 3:
loss: 0.717543
1x1_loss: 0.227051
2x2_loss: 0.293175
2x2_L_loss: 0.197317
1x1_acc: 0.655058
2x2_acc: 0.548922
2x2_L_acc: 0.796020


Warmup:
loss: 1.304628
1x1_loss: 0.187634
2x2_loss: 0.221285
2x2_L_loss: 0.183802
1x2_loss: 0.711907
1x1_acc: 0.759815
2x2_acc: 0.685912
2x2_L_acc: 0.857968
1x2_acc: 0.303695

Fine Tune:
loss: 1.384434
1x1_loss: 0.238413
2x2_loss: 0.310190
2x2_L_loss: 0.141045
1x2_loss: 0.694786
1x1_acc: 0.759815
2x2_acc: 0.685912
2x2_L_acc: 0.857968
1x2_acc: 0.303695

------------------

More layers!
loss: 0.816974
1x1_loss: 0.328940
2x2_loss: 0.297043
2x2_L_loss: 0.190991
1x1_acc: 0.558872
2x2_acc: 0.543947
2x2_L_acc: 0.794362


Warm up:
loss: 1.318313
1x1_loss: 0.263323
2x2_loss: 0.241457
2x2_L_loss: 0.145701
1x2_loss: 0.667832
1x1_acc: 0.639723
2x2_acc: 0.672055
2x2_L_acc: 0.855658
1x2_acc: 0.303695

Fine tune:
loss: 1.410376
1x1_loss: 0.244678
2x2_loss: 0.320125
2x2_L_loss: 0.145127
1x2_loss: 0.700446
1x1_acc: 0.759815
2x2_acc: 0.685912
2x2_L_acc: 0.857968
1x2_acc: 0.303695

----------------------------
Maybe fixed wrong files?

first 3:
loss: 0.911870
1x1_loss: 0.375763
2x2_loss: 0.356505
2x2_L_loss: 0.179602
1x1_acc: 0.626866
2x2_acc: 0.422886
2x2_L_acc: 0.786070

loss: 1.532328
1x1_loss: 0.269031
2x2_loss: 0.360128
2x2_L_loss: 0.159352
1x2_loss: 0.743817
1x1_acc: 0.734411
2x2_acc: 0.418014
2x2_L_acc: 0.833718
1x2_acc: 0.303695

loss: 1.407066
1x1_loss: 0.242099
2x2_loss: 0.325721
2x2_L_loss: 0.145222
1x2_loss: 0.694023
1x1_acc: 0.759815
2x2_acc: 0.685912
2x2_L_acc: 0.857968
1x2_acc: 0.303695

------------------------------
Drop warm up and fine tune learning rates
loss: 1.025193
1x1_loss: 0.448105
2x2_loss: 0.385739
2x2_L_loss: 0.191349
1x1_acc: 0.454395
2x2_acc: 0.441128
2x2_L_acc: 0.779436

loss: 1.449544
1x1_loss: 0.399077
2x2_loss: 0.336091
2x2_L_loss: 0.143702
1x2_loss: 0.570675
1x1_acc: 0.484988
2x2_acc: 0.493072
2x2_L_acc: 0.841801
1x2_acc: 0.303695

loss: 1.437411
1x1_loss: 0.251210
2x2_loss: 0.332438
2x2_L_loss: 0.148332
1x2_loss: 0.705432
1x1_acc: 0.759815
2x2_acc: 0.685912
2x2_L_acc: 0.857968
1x2_acc: 0.303695

drop fine tune learning rate again
loss: 1.505794
1x1_loss: 0.399077
2x2_loss: 0.336091
2x2_L_loss: 0.143702
1x2_loss: 0.626925
1x1_acc: 0.484988
2x2_acc: 0.493072
2x2_L_acc: 0.841801
1x2_acc: 0.303695

loss: 1.512105
1x1_loss: 0.248747
2x2_loss: 0.331735
2x2_L_loss: 0.158776
1x2_loss: 0.772847
1x1_acc: 0.759815
2x2_acc: 0.685912
2x2_L_acc: 0.857968
1x2_acc: 0.303695

-------------------------------
Really drop learning rate
loss: 0.825730
1x1_loss: 0.289350
2x2_loss: 0.375438
2x2_L_loss: 0.160942
1x1_acc: 0.482587
2x2_acc: 0.535655
2x2_L_acc: 0.794362

loss: 1.189794
1x1_loss: 0.259642
2x2_loss: 0.276828
2x2_L_loss: 0.123543
1x2_loss: 0.529781
1x1_acc: 0.545035
2x2_acc: 0.661663
2x2_L_acc: 0.855658
1x2_acc: 0.304850

loss: 1.086052
1x1_loss: 0.223181
2x2_loss: 0.271582
2x2_L_loss: 0.121393
1x2_loss: 0.469895
1x1_acc: 0.654734
2x2_acc: 0.669746
2x2_L_acc: 0.856813
1x2_acc: 0.304850
--------------------------
loss: 1.144560
1x1_loss: 0.259642
2x2_loss: 0.276828
2x2_L_loss: 0.123543
1x2_loss: 0.484547
1x1_acc: 0.545035
2x2_acc: 0.661663
2x2_L_acc: 0.855658
1x2_acc: 0.307159


loss: 1.045911
1x1_loss: 0.222838
2x2_loss: 0.271233
2x2_L_loss: 0.121531
1x2_loss: 0.430309
1x1_acc: 0.655889
2x2_acc: 0.669746
2x2_L_acc: 0.856813
1x2_acc: 0.304850

----------------------------
Constant weight initialize = 0.1
loss: 1.297531
1x1_loss: 0.259642
2x2_loss: 0.276828
2x2_L_loss: 0.123543
1x2_loss: 0.637518
1x1_acc: 0.545035
2x2_acc: 0.661663
2x2_L_acc: 0.855658
1x2_acc: 0.300231

loss: 1.151104
1x1_loss: 0.223733
2x2_loss: 0.271452
2x2_L_loss: 0.121433
1x2_loss: 0.534486
1x1_acc: 0.653580
2x2_acc: 0.669746
2x2_L_acc: 0.856813
1x2_acc: 0.301386

----------------------------
Constant weight = Average of one of the other tasks
loss: 0.877972
1x1_loss: 0.259642
2x2_loss: 0.276828
2x2_L_loss: 0.123543
1x2_loss: 0.217959
1x1_acc: 0.545035
2x2_acc: 0.661663
2x2_L_acc: 0.855658
1x2_acc: 0.696305

loss: 0.834271
1x1_loss: 0.223271
2x2_loss: 0.271827
2x2_L_loss: 0.121289
1x2_loss: 0.217884
1x1_acc: 0.659353
2x2_acc: 0.668591
2x2_L_acc: 0.856813
1x2_acc: 0.696305


------------------------------
Bring lr back up again
loss: 0.891694
1x1_loss: 0.259642
2x2_loss: 0.276828
2x2_L_loss: 0.123543
1x2_loss: 0.231681
1x1_acc: 0.545035
2x2_acc: 0.661663
2x2_L_acc: 0.855658
1x2_acc: 0.696305

loss: 0.922772
1x1_loss: 0.225983
2x2_loss: 0.314059
2x2_L_loss: 0.149743
1x2_loss: 0.232988
1x1_acc: 0.759815
2x2_acc: 0.685912
2x2_L_acc: 0.857968
1x2_acc: 0.696305
better! (ish)

------------------------------
RandomNormal, stddev average of one other task weights
loss: 1.233968
1x1_loss: 0.259642
2x2_loss: 0.276828
2x2_L_loss: 0.123543
1x2_loss: 0.573954
1x1_acc: 0.545035
2x2_acc: 0.661663
2x2_L_acc: 0.855658
1x2_acc: 0.303695

loss: 1.477022
1x1_loss: 0.227317
2x2_loss: 0.319849
2x2_L_loss: 0.149215
1x2_loss: 0.780640
1x1_acc: 0.759815
2x2_acc: 0.685912
2x2_L_acc: 0.857968
1x2_acc: 0.303695
(bad!)

---------------------------
Remove reduce on plateau
loss: 6.717033
1x1_loss: 0.259642
2x2_loss: 0.276828
2x2_L_loss: 0.123543
1x2_loss: 6.057020
1x1_acc: 0.545035
2x2_acc: 0.661663
2x2_L_acc: 0.855658
1x2_acc: 0.198614

loss: 1.681072
1x1_loss: 0.191280
2x2_loss: 0.269377
2x2_L_loss: 0.125637
1x2_loss: 1.094777
1x1_acc: 0.759815
2x2_acc: 0.685912
2x2_L_acc: 0.857968
1x2_acc: 0.367206

-----------------------------
Back to constant initialize
loss: 0.891694
1x1_loss: 0.259642
2x2_loss: 0.276828
2x2_L_loss: 0.123543
1x2_loss: 0.231681
1x1_acc: 0.545035
2x2_acc: 0.661663
2x2_L_acc: 0.855658
1x2_acc: 0.696305

loss: 0.923162
1x1_loss: 0.225627
2x2_loss: 0.314275
2x2_L_loss: 0.150271
1x2_loss: 0.232988
1x1_acc: 0.759815
2x2_acc: 0.685912
2x2_L_acc: 0.857968
1x2_acc: 0.696305
(Better! Still pretty bad though)

------------------------
Use real legos for train and test
loss: 0.789276
1x1_loss: 0.276093
2x2_loss: 0.327937
2x2_L_loss: 0.185247
1x1_acc: 0.582090
2x2_acc: 0.535655
2x2_L_acc: 0.792703

loss: 1.296469
1x1_loss: 0.218641
2x2_loss: 0.262363
2x2_L_loss: 0.146809
1x2_loss: 0.668655
1x1_acc: 0.672055
2x2_acc: 0.668591
2x2_L_acc: 0.853349
1x2_acc: 0.303695

loss: 1.509036
1x1_loss: 0.239933
2x2_loss: 0.322379
2x2_L_loss: 0.150566
1x2_loss: 0.796158
1x1_acc: 0.757506
2x2_acc: 0.685912
2x2_L_acc: 0.856813
1x2_acc: 0.303695

----------------------------
loss: 2.767307
1x1_loss: 0.695337
2x2_loss: 0.383494
2x2_L_loss: 0.161629
1x2_loss: 1.526847
1x1_acc: 0.427252
2x2_acc: 0.593533
2x2_L_acc: 0.825635
1x2_acc: 0.277136

----------
Counts:  [0, 13, 0, 195]
Counts:  [0, 6, 0, 266]
Counts:  [0, 5, 0, 118]
Counts:  [0, 5, 0, 258]